{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WaterLevel_correct.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDE6bX8Fg9Dd"
      },
      "source": [
        "## **The code below is to**\n",
        "**a. Correct for water level logger drift,**\n",
        "\n",
        "**b. Correct for SC sensor drift,**\n",
        "\n",
        "**c. Check accuracy of logger deployment, and**\n",
        "\n",
        "**d. Add the deployment block information to the block table.**\n",
        "\n",
        "Read the code text and comments embedded in each code block carefully (denoted by '#'), as some components require user input (initials, manual water level measurements, etc.).\n",
        "\n",
        "\n",
        "Code blocks below denoted with (^) indicate they're to be run only if using a local runtime\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3-WxnGaQ8Rt"
      },
      "source": [
        "**If working through Google Colab**\n",
        "\n",
        "You will be prompted to click on a link that will show you an authorization code. copy the authorization code into the input box below. You also may be asked to allow Google Colab access to your Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-maZyicQ34i"
      },
      "source": [
        "from google.colab import drive, auth\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib notebook\n",
        "import numpy as np\n",
        "from datetime import date\n",
        "import csv\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBkuB1R1lxAF"
      },
      "source": [
        "Path names will be the same, but specify the file name you are working on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89PXAr6klvbx"
      },
      "source": [
        "#Change 'file' below to whatever file you're working on\n",
        "file='MBHF1_20210416_LTC_baroC.csv'\n",
        "\n",
        "path='/content/drive/My Drive/Water/preprocess_files/'\n",
        "endpath='/content/drive/My Drive/Water/postprocess_files/'\n",
        "\n",
        "df=pd.read_csv(path+file,index_col=[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIrvHpxclYDv"
      },
      "source": [
        "**(^) If working from a local runtime on you computer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjmDG_u_cteP",
        "outputId": "0fddd1a1-7879-4989-a0ed-a46de51d23fe"
      },
      "source": [
        "#For working on local machine\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib notebook\n",
        "import numpy as np\n",
        "from datetime import date\n",
        "import csv\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting plotly\n",
            "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
            "Requirement already satisfied: six in c:\\users\\mcquiggan\\appdata\\local\\continuum\\anaconda3\\envs\\py38_x32\\lib\\site-packages (from plotly) (1.15.0)\n",
            "Collecting retrying>=1.3.3\n",
            "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
            "Building wheels for collected packages: retrying\n",
            "  Building wheel for retrying (setup.py): started\n",
            "  Building wheel for retrying (setup.py): finished with status 'done'\n",
            "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=082b5bb2bd81b6af34d734c2aaf5e1f4d3f55d237db95676c15b56c817ff8ccd\n",
            "  Stored in directory: c:\\users\\mcquiggan\\appdata\\local\\pip\\cache\\wheels\\c4\\a7\\48\\0a434133f6d56e878ca511c0e6c38326907c0792f67b476e56\n",
            "Successfully built retrying\n",
            "Installing collected packages: retrying, plotly\n",
            "Successfully installed plotly-4.14.3 retrying-1.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdaZFIcFJ8Rq"
      },
      "source": [
        "(^) Path names will be the same, but specify the file name you are working on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jFapkHBcteR"
      },
      "source": [
        "#Change 'file' below to whatever file you're working on\n",
        "file='MBM1_20210416_LTC_baroC.csv'\n",
        "\n",
        "path='G:/Shared drives/CZN_HydroGroup/Water/preprocess_files/'\n",
        "endpath='G:/Shared drives/CZN_HydroGroup/Water/postprocess_files/'\n",
        "\n",
        "df=pd.read_csv(path+file,index_col=[0])\n",
        "df.index=pd.to_datetime(df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeZOm4KDxZAi"
      },
      "source": [
        "For **Solinst brand loggers**, run the 1 code block below. Skip this if you're using a different brand logger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vR7IVPRexfTN",
        "outputId": "4c7440d1-5a77-4aa0-e7f9-79e25a71975d"
      },
      "source": [
        "#Add extra DateTime field for interactive plot\n",
        "df['DateTime']=pd.to_datetime(df['Date']+\" \"+df['Time'])\n",
        "\n",
        "#Find start and end dates from logger file\n",
        "start_date=df.index[0]\n",
        "end_date=df.index[len(df.index)-1]\n",
        "print('Need manual measurements collected on '+start_date+' and '+end_date)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can only concatenate str (not \"Timestamp\") to str",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-15-0eb652f1ad6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Need manual measurements collected on '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' and '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"Timestamp\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7Zmz2Nju39V"
      },
      "source": [
        "**Enter field water level measurements as variables below.**\n",
        "\n",
        "These values can be found in both the Manual_msmt.gsheet OR in the watlev table in the AccessDB.\n",
        "\n",
        "start_lev - the manual measurement collected when you deployed the sensor\n",
        "\n",
        "end_lev - the manual measurement collected when you stopped and downloaded the sensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GXdjwSq5649"
      },
      "source": [
        "start_lev=0.966216\n",
        "end_lev=start_lev+-0.18419"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2l2RMAFS35_"
      },
      "source": [
        "(^) Plot water level data. Will pop up in a new browser window if using a local runtime, otherwise use Excel for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkzGT13VSf0u"
      },
      "source": [
        "#%matplotlib widget\n",
        "df.plot(x='DateTime',y='LOGGER_mWater_corr',style='.',rot=45)\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#To see first 5 rows of dataframe\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_JqA58lS1ac"
      },
      "source": [
        "#To see last 5 rows of dataframe\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnvRcWT7TEr6"
      },
      "source": [
        "\n",
        "---\n",
        "##**Clean up the data**##\n",
        "\n",
        "**Below are some common corrections to remove noisy or rogue data points**\n",
        "\n",
        "All require some manual entry (i.e. number of rows, date and time). Zoom in and pan through the interactive plot to find info for specific points or periods of data. You can run one or more separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VilcMiJ5eT6r",
        "scrolled": true
      },
      "source": [
        "#To remove a specified number of records at the start of the file\n",
        "#Enter the number of rows below as start_del\n",
        "start_del=2\n",
        "df=df.iloc[start_del:]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I2FuKhTeYNT"
      },
      "source": [
        "#To remove a specified number of records at the end of the file\n",
        "#Enter the number of rows below as end_del\n",
        "end_del=1\n",
        "df=df.iloc[:-end_del]\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v48H9Sw6eaVH"
      },
      "source": [
        "#To interpolate values between two records (i.e. smooth over a point)\n",
        "#Change the date and time to that of whatever point you want to smooth over\n",
        "#Can do this multiple times for multiple points and the interpolate function will do all at once\n",
        "point=(df.index.get_loc('2021-02-03 11:00:00'))\n",
        "df['LOGGER_mWater_corr'][point]=np.nan\n",
        "df['LOGGER_mWater_corr']=df['LOGGER_mWater_corr'].interpolate(axis=0)\n",
        "print(df['LOGGER_mWater_corr'][point])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIdShYKoTLaZ"
      },
      "source": [
        "#To interpolate values over multiple records (i.e. interpolate over multiple consecutive records)\n",
        "#Change the date and time for the first (first_pt) and last (last_pt) of the interval you want to change\n",
        "first_pt=df.index.get_loc('2020-12-01 14:15:00')\n",
        "last_pt=df.index.get_loc('2020-12-01 14:45:00')+1\n",
        "df['LOGGER_mWater_corr'][first_pt:last_pt]=np.nan\n",
        "df['LOGGER_mWater_corr']=df['LOGGER_mWater_corr'].interpolate(axis=0)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgP8jNv_TPzj"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "##**Correct water levels**##\n",
        "\n",
        "\n",
        "**After removing and cleaning all noisy data, run the code below to correct water level values for sensor drift**\n",
        "\n",
        "Your starting level (first record value) should match your starting manual measurement and your ending level (last record value) should match your end manual measurement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp5x2Q4ETUxJ"
      },
      "source": [
        "df['LOGGER_mDTW_corr']=df['LOGGER_mWater_corr']\n",
        "n=len(df['LOGGER_mWater_corr'])-1\n",
        "LTCinit=df['LOGGER_mWater_corr'][0]\n",
        "LTCend=df['LOGGER_mWater_corr'][n]\n",
        "df['LOGGER_mDTW_corr']=start_lev-(df['LOGGER_mWater_corr']-LTCinit)\n",
        "R1=df['LOGGER_mDTW_corr'][0]\n",
        "R2=df['LOGGER_mDTW_corr'][n]\n",
        "acc=round((end_lev-R2)-(start_lev-R1),3)\n",
        "K=acc/(n-1)\n",
        "\n",
        "new_lc=[]\n",
        "for index,val in enumerate(df['LOGGER_mDTW_corr'],start=1):\n",
        "    corr=K*(index-1)\n",
        "    new=round(val+corr,3)\n",
        "    new_lc.append(new)\n",
        "\n",
        "df['LOGGER_mDTW_corr']=new_lc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IbprL-IKwc7"
      },
      "source": [
        "---\n",
        "##**Correct SC for sensor drift**##\n",
        "\n",
        "Use calibration check and calibration values to complete this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dmC6exVKz8I"
      },
      "source": [
        "#Enter starting calibration value and ending calibration check value\n",
        "start_std=1413\n",
        "start_cal=1413\n",
        "end_std=1413\n",
        "end_cal= 1413\n",
        "\n",
        "n=len(df['LOGGER_SC'])-1\n",
        "K1=start_std/start_cal\n",
        "K2=end_std/end_cal\n",
        "drift=round(K1-K2,4)\n",
        "dK=(K2-K1)/(n-1)\n",
        "\n",
        "new_sc=[]\n",
        "for index,val in enumerate(df['LOGGER_SC'],start=1):\n",
        "    corr=1+(dK/K1)*(index-1)\n",
        "    new=round(val*corr,3)\n",
        "    new_sc.append(new)\n",
        "\n",
        "df['LOGGER_SC']=new_sc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg5jX1ncT1xm"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "##**Add deployment record data to block and data tables**##\n",
        "\n",
        "This will call up the block.csv file and add a new record. Run #1-5 for EACH MEASUREMENT VARIABLE. For example, if your logger is collecting temperature, level and SC, the following #1-5 blocks must be run three time separately. Make sure you change the variables in #1 each time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8czhyi37fvAG"
      },
      "source": [
        "**#1. Manually enter some variables below**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUG9GI1ydefO"
      },
      "source": [
        "#Enter the variables below\n",
        "initials='RWM'\n",
        "dat_type='T'\n",
        "matrix='W'\n",
        "unit='DC'\n",
        "sensor='M3001'\n",
        "sensor_sn=1080544\n",
        "datum='TOC'\n",
        "interval=15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRpk2NuiuSok"
      },
      "source": [
        "**#2. Open block table through (a) Colab or (b) local runtime**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MN4ein9r-sh"
      },
      "source": [
        "  (a) Open block table on the Shared Drive **if working through Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k_2JRjrYCa_"
      },
      "source": [
        "df_block=pd.read_csv('/content/drive/My Drive/Water/data_tables/block.csv')\n",
        "print(df_block)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8iFrDAvr6zn"
      },
      "source": [
        "(b) (^) Open block table **if in a local runtime**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpWT_qtar0_D"
      },
      "source": [
        "df_block=pd.read_csv('G:/Shared drives/CZN_HydroGroup/Water/data_tables/block.csv')\n",
        "print(df_block)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQcE6je6ugY7"
      },
      "source": [
        "**#3. Calculate some variables**\n",
        "\n",
        "Do not manually enter anything below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDI2PtcpT4Z8"
      },
      "source": [
        "#Get block table info\n",
        "block_start_time=df.index[0]\n",
        "block_end_time=df.index[len(df.index)-1]\n",
        "site_id=file.split('_')[0]\n",
        "blockno=df_block['blockno'].max()+1\n",
        "ind1=df_block['index2'].max()+1\n",
        "ind2=ind1+n\n",
        "process_date=date.today().strftime('%m/%d/%Y')\n",
        "\n",
        "def find_acc():\n",
        "    if dat_type=='L':\n",
        "        return (round((end_lev-R2)-(start_lev-R1),3))\n",
        "    elif dat_type=='T':\n",
        "        return np.nan\n",
        "    elif dat_type=='C':\n",
        "        return np.nan\n",
        "    else:\n",
        "        print('You have entered an invalid data type')\n",
        "\n",
        "acc=find_acc()\n",
        "\n",
        "def find_drift():\n",
        "    if dat_type=='L':\n",
        "        return np.nan\n",
        "    elif dat_type=='T':\n",
        "        return np.nan\n",
        "    elif dat_type=='C':\n",
        "        return (round(K1-K2,4))\n",
        "    else:\n",
        "        print('You have entered an invalid data type')\n",
        "\n",
        "drift=find_drift()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCFzf-Y1usGM"
      },
      "source": [
        "**#4. Append new deployment record to existing block table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AHWKzkbT-s-"
      },
      "source": [
        "#Append to block table\n",
        "df_block=df_block.append({'blockno':blockno,\n",
        "                          'site_id':site_id,\n",
        "                          'start_time':block_start_time,\n",
        "                          'index1':ind1,\n",
        "                          'end_time':block_end_time,\n",
        "                          'index2':ind2,\n",
        "                          'matrix':matrix,\n",
        "                          'data_type':dat_type,\n",
        "                          'sensor':sensor,\n",
        "                          'sensor_sn':sensor_sn,\n",
        "                          'unit':unit,\n",
        "                          'interval':interval,\n",
        "                          'mp_datum':datum,\n",
        "                          'accuracy':acc,\n",
        "                          'drift':drift,\n",
        "                          'process_initials':initials,\n",
        "                          'process_date':process_date},ignore_index=True)\n",
        "\n",
        "#Check block table and make sure the new record looks OK\n",
        "df_block"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT6Q8MNSuxaF"
      },
      "source": [
        "**#5. Commit this new record to the table**\n",
        "\n",
        "No need to append here, since you brought in the existing file that contained previous records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wePVmN5E83sC"
      },
      "source": [
        "df_block.to_csv('/content/drive/My Drive/Water/data_tables/block.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIi70PUFtRUU"
      },
      "source": [
        "---\n",
        "\n",
        "##**Add the actual data values to the data.csv file**##\n",
        "\n",
        "Each variable must be done separately, but they will be appended to the existing file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsihRyp4SOGg"
      },
      "source": [
        "#If data is water levels\n",
        "df_data=pd.read_csv('/content/drive/My Drive/Water/data_tables/data.csv')\n",
        "df_data['index']=[*range(ind1,ind2+1,1)]\n",
        "df_data['blockno']=blockno\n",
        "df_data['amount']=df['LOGGER_mDTW_corr'].to_list()\n",
        "df_data=df_data.to_csv('/content/drive/My Drive/Water/data_tables/data.csv',mode='a',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OFTuChfSUdH"
      },
      "source": [
        "#If data is conductivity\n",
        "df_data=pd.read_csv('/content/drive/My Drive/Water/data_tables/data.csv')\n",
        "df_data['index']=[*range(ind1,ind2+1,1)]\n",
        "df_data['blockno']=blockno\n",
        "df_data['amount']=df['LOGGER_SC'].to_list()\n",
        "df_data=df_data.to_csv('/content/drive/My Drive/Water/data_tables/data.csv',mode='a',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_w0FMQ4HO1l"
      },
      "source": [
        "#If data is temperature\n",
        "df_data=pd.read_csv('/content/drive/My Drive/Water/data_tables/data.csv')\n",
        "df_data['index']=[*range(ind1,ind2+1,1)]\n",
        "df_data['blockno']=blockno\n",
        "df_data['amount']=df['LOGGER_Temp_C'].to_list()\n",
        "df_data=df_data.to_csv('/content/drive/My Drive/Water/data_tables/data.csv',mode='a',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoYd3PibJTWd"
      },
      "source": [
        "##**Move the logger file to the Post Process folder**##\n",
        "\n",
        "This comes after you've finished adding records to the block table AND adding to the data table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjlMQRL8Diwp"
      },
      "source": [
        "#Save to csv with '_levelCorrect' suffix and move to postprocess\n",
        "df=df.to_csv(endpath+file.split('.')[0]+'_levC.csv',index=True)\n",
        "os.remove(path+file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
