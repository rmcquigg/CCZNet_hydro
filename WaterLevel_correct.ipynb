{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WaterLevel_correct.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxaSBhy22tPzaOG9dUzqI0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDE6bX8Fg9Dd"
      },
      "source": [
        "# **The code below is to correct for water level logger drift, check accuracy of logger deployment and add the deployment block information to the block table.**\r\n",
        "\r\n",
        "It does not require any Python knowledge, but it does require Python and certain packages to be installed on your computer. Read the code comments embedded in each code block carefully (denoted by '#'), as some components require user input (initials, manual water level measurements, etc.).\r\n",
        "\r\n",
        "So far, this is tailored to *Solinst brand* data logger files. We will need some extra components for other brands, but at  this point I don't know what those data files look like.\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3-WxnGaQ8Rt"
      },
      "source": [
        "**Connect to Shared Drive**\r\n",
        "\r\n",
        "You will be prompted to click on a link that will show you an authorization code. copy the authorization code into the input box below. You also may be asked to allow Google Colab access to your Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-maZyicQ34i"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjZqUNbrRHWY"
      },
      "source": [
        "**Import packages**\r\n",
        "\r\n",
        "You may need to install these packages on your computer, if they're not already. To do this through a command prompt on Windows, Python needs to be discoverable by your PATH variable (add the directory location of Python OR Python packages within a virtual environment to your system user variables). You can then either install directly or use pip installer (\"pip install *package name*\") through the terminal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAcyDggvROGd"
      },
      "source": [
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib auto\r\n",
        "import numpy as np\r\n",
        "from datetime import date\r\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYb7UJ4E7Cxr"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append('/content/drive/My Drive/CZN_hydro/Water/process_scripts')\r\n",
        "import find_first_row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdaZFIcFJ8Rq"
      },
      "source": [
        "**Name the file you're working on as a variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPEGJvqXLmxW"
      },
      "source": [
        "file='Eb41-18_200807_LTC.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z0yl1po7mN2"
      },
      "source": [
        "#This part is if you need to skip some rows at the beginning of the file to bring it into a df (i.e. logger metadata at the top)\r\n",
        "#Change the first part of the filepath, if needed (maybe preprocess instead of raw?)\r\n",
        "ffr=find_first_row.first_row('/content/drive/My Drive/CZN_hydro/Water/raw_files/'+file)\r\n",
        "print(ffr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIGImj6uK-cn"
      },
      "source": [
        "**Bring the file in as a dataframe**\r\n",
        "\r\n",
        "To skip rows, add \"skiprows=ffr\" to the pd.read_csv arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nSQ9ZImReuy"
      },
      "source": [
        "path='/content/drive/My Drive/CZN_hydro/Water/preprocess_files/'\r\n",
        "df=pd.read_csv(path+file)\r\n",
        "\r\n",
        "start_date=df['Date'][0]\r\n",
        "end_date=df['Date'][len(df['Date'])-1]\r\n",
        "print('Need manual measurements collected on '+start_date+' and '+end_date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSXmPaOuHlVw"
      },
      "source": [
        "with open('/content/drive/My Drive/CZN_hydro/Water/raw_files/'+file,encoding='gbk') as f:\r\n",
        "        csv.reader(f)\r\n",
        "        substring='Date'\r\n",
        "        for i, row in enumerate(f):\r\n",
        "            if substring in row:\r\n",
        "                #return i\r\n",
        "                print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H49hsNEASMAe"
      },
      "source": [
        "Lookup manual measurements and add as variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVYExXN5SJJ-"
      },
      "source": [
        "start_lev=2.90\r\n",
        "end_lev=2.31\r\n",
        "\r\n",
        "#Combine date and time fields, round to nearest 15 min increment 00:15:00) and set to index\r\n",
        "df['DateTime']=pd.to_datetime(df['Date']+\" \"+df['Time'])\r\n",
        "df['DateTime']=pd.to_datetime(df['DateTime']).dt.round('15min').dt.strftime('%m/%d/%Y %H:%M:%S')\r\n",
        "df=df.set_index('DateTime')\r\n",
        "#Add extra DateTime field for interactive plot\r\n",
        "df['DateTime']=pd.to_datetime(df['Date']+\" \"+df['Time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2l2RMAFS35_"
      },
      "source": [
        "Plot Water Level data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkzGT13VSf0u"
      },
      "source": [
        "df.plot(x='DateTime',y='LEVEL',style='.',rot=45)\r\n",
        "plt.grid()\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnvRcWT7TEr6"
      },
      "source": [
        "**Below are some common corrections to remove noisy or rogue data points**\r\n",
        "\r\n",
        "All require some manual entry (i.e. number of rows, date and time). Zoom in and pan through the interactive plot to find info for specific points or periods of data. You can run one or more separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VilcMiJ5eT6r"
      },
      "source": [
        "#To remove a specified number of records at the start of the file\r\n",
        "#Enter the number of rows below as start_del\r\n",
        "start_del=1\r\n",
        "df=df.iloc[start_del:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I2FuKhTeYNT"
      },
      "source": [
        "#To remove a specified number of records at the end of the file\r\n",
        "#Enter the number of rows below as end_del\r\n",
        "end_del=1\r\n",
        "df=df.iloc[:-end_del]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v48H9Sw6eaVH"
      },
      "source": [
        "#To interpolate values between two records (i.e. smooth over a point)\r\n",
        "#Change the date and time to that of whatever point you want to smooth over\r\n",
        "#Can do this multiple times for multiple points and the interpolate function will do all at once\r\n",
        "point=(df.index.get_loc('08/28/2020 14:30:00'))\r\n",
        "df['LEVEL'][point]=np.nan\r\n",
        "df['LEVEL']=df['LEVEL'].interpolate(axis=0)\r\n",
        "print(df['LEVEL'][point])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIdShYKoTLaZ"
      },
      "source": [
        "#To interpolate values over multiple records (i.e. interpolate over multiple consecutive records)\r\n",
        "#Change the date and time for the first (first_pt) and last (last_pt) of the interval\r\n",
        "first_pt=df.index.get_loc('08/28/2020 14:30:00')\r\n",
        "last_pt=df.index.get_loc('08/28/2020 15:30:00')+1\r\n",
        "df['LEVEL'][first_pt:last_pt]=np.nan\r\n",
        "df['LEVEL']=df['LEVEL'].interpolate(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgP8jNv_TPzj"
      },
      "source": [
        "**After removing and cleaning all noisy data, run the code below to correct water level values for sensor drift**\r\n",
        "\r\n",
        "Your starting level (first record value) should match your starting manual measurement and your ending level (last record value) should match your end manual measurement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp5x2Q4ETUxJ"
      },
      "source": [
        "df['LEVEL_corr']=df['LEVEL']\r\n",
        "n=len(df['LEVEL'])-1\r\n",
        "LTCinit=df['LEVEL'][0]\r\n",
        "LTCend=df['LEVEL'][n]\r\n",
        "acc=(end_lev-LTCend)-(start_lev-LTCinit)\r\n",
        "K=acc/(n-1)\r\n",
        "\r\n",
        "new_lc=[]\r\n",
        "for index,val in enumerate(df['LEVEL'],start=1):\r\n",
        "    corr=(start_lev-LTCinit)+K*(index-1)\r\n",
        "    new=round(val+corr,2)\r\n",
        "    new_lc.append(new)\r\n",
        "\r\n",
        "df['LEVEL_corr']=new_lc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjlMQRL8Diwp"
      },
      "source": [
        "#Saved dataframe to a .csv file with the same filename as before\r\n",
        "#Assumption is you'll do SC processing next and THEN it will be moved to\r\n",
        "df=df.to_csv(path+file,index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg5jX1ncT1xm"
      },
      "source": [
        "**Add record data to block table**\r\n",
        "\r\n",
        "First, allow Colab to directly access a gsheet.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEDuDtfBGJzh"
      },
      "source": [
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "import gspread\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "gc=gspread.authorize(GoogleCredentials.get_application_default())\r\n",
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehxAEcxIE3Af"
      },
      "source": [
        "wb=gc.open_by_url('https://docs.google.com/spreadsheets/d/1A9HW5zrQf63nOUvTBVBqTuX2k4BdMwE_j2VAi5pDRaU/edit#gid=0')\r\n",
        "sheet=wb.worksheet('block')\r\n",
        "data=sheet.get_all_values()\r\n",
        "df_block=pd.DataFrame(data)\r\n",
        "df_block.columns=df_block.iloc[0]\r\n",
        "df_block=df_block.iloc[1:]\r\n",
        "#Replace blanks with np.nan\r\n",
        "df_block=df_block.replace(r'^\\s*$',np.nan,regex=True)\r\n",
        "\r\n",
        "new_df_schema = {\r\n",
        "      'BlockNo':df_block['BlockNo'].astype(int),\r\n",
        "      'Site_id':df_block['Site_id'].astype(str),\r\n",
        "      'Start_time':df_block['Start_time'].astype(str),\r\n",
        "      'Index1':df_block['Index1'].astype(int),\r\n",
        "      'End_time':df_block['End_time'].astype(str),\r\n",
        "      'Index2':df_block['Index2'].astype(int),\r\n",
        "      'Type':df_block['Type'].astype(str),\r\n",
        "      'Device':df_block['Device'].astype(str),\r\n",
        "      'Sensor_sn':df_block['Sensor_sn'].astype(str),\r\n",
        "      'Unit':df_block['Unit'].astype(str),\r\n",
        "      'Interval':df_block['Interval'].astype(int),\r\n",
        "      'Datum':df_block['Datum'].astype(str),\r\n",
        "      'Accuracy':df_block['Accuracy'].astype(float),\r\n",
        "      'Drift':df_block['Drift'].astype(float),\r\n",
        "      'Process_initials':df_block['Process_initials'].astype(str),\r\n",
        "      'Process_date':df_block['Process_date'].astype(str)}\r\n",
        "df_block=pd.DataFrame(new_df_schema)\r\n",
        "print(df_block)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8czhyi37fvAG"
      },
      "source": [
        "Manually enter some variables below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUG9GI1ydefO"
      },
      "source": [
        "#Enter the variables below\r\n",
        "initials='RWM' \r\n",
        "dat_type='W'\r\n",
        "device='SolinstM3001'\r\n",
        "sensor_sn=89864567\r\n",
        "unit='F'\r\n",
        "datum='TOC'\r\n",
        "interval=15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmLzQdKiI2aK"
      },
      "source": [
        "Let the script figure out some variables for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDI2PtcpT4Z8"
      },
      "source": [
        "#Get block table info\r\n",
        "block_start_time=df_block.index[0]\r\n",
        "block_end_time=df_block.index[len(df_block['Date'])-1]\r\n",
        "site_id=file.split('_')[0]\r\n",
        "blockno=df_block['BlockNo'].max()+1\r\n",
        "ind1=df_block['Index2'].max()+1\r\n",
        "ind2=ind1+n\r\n",
        "process_date=date.today().strftime('%Y-%m-%d')\r\n",
        "\r\n",
        "#This function will eventually move to a separate file to \"clean\" this code up\r\n",
        "def find_drift():\r\n",
        "    if dat_type=='W':\r\n",
        "        return np.nan\r\n",
        "    elif dat_type=='T':\r\n",
        "        return np.nan\r\n",
        "    elif dat_type=='C':\r\n",
        "        return (end_cal-start_cal)\r\n",
        "    else:\r\n",
        "        print('You have entered an invalid data type')\r\n",
        "\r\n",
        "drift=find_drift()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AHWKzkbT-s-"
      },
      "source": [
        "#Append to block table\r\n",
        "df_block=df_block.append({'BlockNo':blockno,\r\n",
        "                          'Site_id':site_id,\r\n",
        "                          'Start_time':block_start_time,\r\n",
        "                          'Index1':ind1,\r\n",
        "                          'End_time':block_end_time,\r\n",
        "                          'Index2':ind2,\r\n",
        "                          'Type':dat_type,\r\n",
        "                          'Device':device,\r\n",
        "                          'Sensor_sn':sensor_sn,\r\n",
        "                          'Unit':unit,\r\n",
        "                          'Interval':interval,\r\n",
        "                          'Datum':datum,\r\n",
        "                          'Accuracy':acc,\r\n",
        "                          'Drift':drift,\r\n",
        "                          'Process_initials':initials,\r\n",
        "                          'Process_date':process_date},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}